{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce753dcb-1e89-4e2f-8e59-94ebd0c3848d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25989908-1eff-4070-8a5e-8e16bb769d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52ae52bd-9a14-4748-b4c9-dea34807f51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "kidney_disease_medical_data = pd.read_csv('../data/kidney_disease.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e64cc726-d804-4ad4-8c1b-72f7c20c4173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mlflow\n",
      "  Downloading mlflow-2.17.1-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting mlflow-skinny==2.17.1 (from mlflow)\n",
      "  Downloading mlflow_skinny-2.17.1-py3-none-any.whl.metadata (30 kB)\n",
      "Requirement already satisfied: Flask<4 in /opt/anaconda3/lib/python3.11/site-packages (from mlflow) (2.2.5)\n",
      "Collecting alembic!=1.10.0,<2 (from mlflow)\n",
      "  Downloading alembic-1.13.3-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting docker<8,>=4.0.0 (from mlflow)\n",
      "  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting graphene<4 (from mlflow)\n",
      "  Downloading graphene-3.4-py2.py3-none-any.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: markdown<4,>=3.3 in /opt/anaconda3/lib/python3.11/site-packages (from mlflow) (3.4.1)\n",
      "Requirement already satisfied: matplotlib<4 in /opt/anaconda3/lib/python3.11/site-packages (from mlflow) (3.8.0)\n",
      "Requirement already satisfied: numpy<3 in /opt/anaconda3/lib/python3.11/site-packages (from mlflow) (1.26.4)\n",
      "Requirement already satisfied: pandas<3 in /opt/anaconda3/lib/python3.11/site-packages (from mlflow) (2.1.4)\n",
      "Requirement already satisfied: pyarrow<18,>=4.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from mlflow) (14.0.2)\n",
      "Requirement already satisfied: scikit-learn<2 in /opt/anaconda3/lib/python3.11/site-packages (from mlflow) (1.2.2)\n",
      "Requirement already satisfied: scipy<2 in /opt/anaconda3/lib/python3.11/site-packages (from mlflow) (1.11.4)\n",
      "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /opt/anaconda3/lib/python3.11/site-packages (from mlflow) (2.0.25)\n",
      "Requirement already satisfied: Jinja2<4,>=2.11 in /opt/anaconda3/lib/python3.11/site-packages (from mlflow) (3.1.3)\n",
      "Collecting gunicorn<24 (from mlflow)\n",
      "  Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting cachetools<6,>=5.0.0 (from mlflow-skinny==2.17.1->mlflow)\n",
      "  Downloading cachetools-5.5.0-py3-none-any.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: click<9,>=7.0 in /opt/anaconda3/lib/python3.11/site-packages (from mlflow-skinny==2.17.1->mlflow) (8.1.7)\n",
      "Requirement already satisfied: cloudpickle<4 in /opt/anaconda3/lib/python3.11/site-packages (from mlflow-skinny==2.17.1->mlflow) (2.2.1)\n",
      "Collecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==2.17.1->mlflow)\n",
      "  Downloading databricks_sdk-0.36.0-py3-none-any.whl.metadata (38 kB)\n",
      "Requirement already satisfied: gitpython<4,>=3.1.9 in /opt/anaconda3/lib/python3.11/site-packages (from mlflow-skinny==2.17.1->mlflow) (3.1.37)\n",
      "Requirement already satisfied: importlib-metadata!=4.7.0,<9,>=3.7.0 in /opt/anaconda3/lib/python3.11/site-packages (from mlflow-skinny==2.17.1->mlflow) (7.0.1)\n",
      "Collecting opentelemetry-api<3,>=1.9.0 (from mlflow-skinny==2.17.1->mlflow)\n",
      "  Downloading opentelemetry_api-1.27.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting opentelemetry-sdk<3,>=1.9.0 (from mlflow-skinny==2.17.1->mlflow)\n",
      "  Downloading opentelemetry_sdk-1.27.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: packaging<25 in /opt/anaconda3/lib/python3.11/site-packages (from mlflow-skinny==2.17.1->mlflow) (23.1)\n",
      "Requirement already satisfied: protobuf<6,>=3.12.0 in /opt/anaconda3/lib/python3.11/site-packages (from mlflow-skinny==2.17.1->mlflow) (3.20.3)\n",
      "Requirement already satisfied: pyyaml<7,>=5.1 in /opt/anaconda3/lib/python3.11/site-packages (from mlflow-skinny==2.17.1->mlflow) (6.0.1)\n",
      "Requirement already satisfied: requests<3,>=2.17.3 in /opt/anaconda3/lib/python3.11/site-packages (from mlflow-skinny==2.17.1->mlflow) (2.31.0)\n",
      "Collecting sqlparse<1,>=0.4.0 (from mlflow-skinny==2.17.1->mlflow)\n",
      "  Downloading sqlparse-0.5.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting Mako (from alembic!=1.10.0,<2->mlflow)\n",
      "  Downloading Mako-1.3.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4 in /opt/anaconda3/lib/python3.11/site-packages (from alembic!=1.10.0,<2->mlflow) (4.9.0)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /opt/anaconda3/lib/python3.11/site-packages (from docker<8,>=4.0.0->mlflow) (2.0.7)\n",
      "Requirement already satisfied: Werkzeug>=2.2.2 in /opt/anaconda3/lib/python3.11/site-packages (from Flask<4->mlflow) (2.2.3)\n",
      "Requirement already satisfied: itsdangerous>=2.0 in /opt/anaconda3/lib/python3.11/site-packages (from Flask<4->mlflow) (2.0.1)\n",
      "Collecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow)\n",
      "  Downloading graphql_core-3.2.5-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow)\n",
      "  Downloading graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.11/site-packages (from Jinja2<4,>=2.11->mlflow) (2.1.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/lib/python3.11/site-packages (from matplotlib<4->mlflow) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/lib/python3.11/site-packages (from matplotlib<4->mlflow) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/lib/python3.11/site-packages (from matplotlib<4->mlflow) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/anaconda3/lib/python3.11/site-packages (from matplotlib<4->mlflow) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/anaconda3/lib/python3.11/site-packages (from matplotlib<4->mlflow) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/lib/python3.11/site-packages (from matplotlib<4->mlflow) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/anaconda3/lib/python3.11/site-packages (from matplotlib<4->mlflow) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.11/site-packages (from pandas<3->mlflow) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/anaconda3/lib/python3.11/site-packages (from pandas<3->mlflow) (2023.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/anaconda3/lib/python3.11/site-packages (from scikit-learn<2->mlflow) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from scikit-learn<2->mlflow) (2.2.0)\n",
      "Collecting google-auth~=2.0 (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.17.1->mlflow)\n",
      "  Downloading google_auth-2.35.0-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/anaconda3/lib/python3.11/site-packages (from gitpython<4,>=3.1.9->mlflow-skinny==2.17.1->mlflow) (4.0.7)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/anaconda3/lib/python3.11/site-packages (from importlib-metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==2.17.1->mlflow) (3.17.0)\n",
      "Collecting deprecated>=1.2.6 (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.17.1->mlflow)\n",
      "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.48b0 (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==2.17.1->mlflow)\n",
      "  Downloading opentelemetry_semantic_conventions-0.48b0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib<4->mlflow) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.17.1->mlflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.17.1->mlflow) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.17.1->mlflow) (2024.2.2)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /opt/anaconda3/lib/python3.11/site-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.17.1->mlflow) (1.14.1)\n",
      "Requirement already satisfied: smmap<5,>=3.0.1 in /opt/anaconda3/lib/python3.11/site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==2.17.1->mlflow) (4.0.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/anaconda3/lib/python3.11/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.17.1->mlflow) (0.2.8)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.17.1->mlflow)\n",
      "  Downloading rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/anaconda3/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.17.1->mlflow) (0.4.8)\n",
      "Downloading mlflow-2.17.1-py3-none-any.whl (26.7 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.7/26.7 MB\u001b[0m \u001b[31m71.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading mlflow_skinny-2.17.1-py3-none-any.whl (5.7 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m58.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m57.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading alembic-1.13.3-py3-none-any.whl (233 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.2/233.2 kB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading graphene-3.4-py2.py3-none-any.whl (114 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.6/114.6 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cachetools-5.5.0-py3-none-any.whl (9.5 kB)\n",
      "Downloading databricks_sdk-0.36.0-py3-none-any.whl (569 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m569.1/569.1 kB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading graphql_core-3.2.5-py3-none-any.whl (203 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.2/203.2 kB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\n",
      "Downloading opentelemetry_api-1.27.0-py3-none-any.whl (63 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.0/64.0 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_sdk-1.27.0-py3-none-any.whl (110 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_semantic_conventions-0.48b0-py3-none-any.whl (149 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.7/149.7 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sqlparse-0.5.1-py3-none-any.whl (44 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.2/44.2 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading Mako-1.3.6-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
      "Downloading google_auth-2.35.0-py2.py3-none-any.whl (208 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.0/209.0 kB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Installing collected packages: sqlparse, rsa, Mako, gunicorn, graphql-core, deprecated, cachetools, opentelemetry-api, graphql-relay, google-auth, docker, alembic, opentelemetry-semantic-conventions, graphene, databricks-sdk, opentelemetry-sdk, mlflow-skinny, mlflow\n",
      "  Attempting uninstall: cachetools\n",
      "    Found existing installation: cachetools 4.2.2\n",
      "    Uninstalling cachetools-4.2.2:\n",
      "      Successfully uninstalled cachetools-4.2.2\n",
      "Successfully installed Mako-1.3.6 alembic-1.13.3 cachetools-5.5.0 databricks-sdk-0.36.0 deprecated-1.2.14 docker-7.1.0 google-auth-2.35.0 graphene-3.4 graphql-core-3.2.5 graphql-relay-3.2.0 gunicorn-23.0.0 mlflow-2.17.1 mlflow-skinny-2.17.1 opentelemetry-api-1.27.0 opentelemetry-sdk-1.27.0 opentelemetry-semantic-conventions-0.48b0 rsa-4.9 sqlparse-0.5.1\n"
     ]
    }
   ],
   "source": [
    "! pip install mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf024c77-7c7b-4bf0-b699-02f878b8594f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/26 01:36:25 INFO mlflow.tracking.fluent: Experiment with name 'model_comparison_experiment' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///Users/david/Documents/Documents%20-%20David%E2%80%99s%20Mac%20Studio/Personal_Projects/Chronic-Kidney-Disease/backend/data_exploration_notebooks/mlruns/147228988099714012', creation_time=1729920985215, experiment_id='147228988099714012', last_update_time=1729920985215, lifecycle_stage='active', name='model_comparison_experiment', tags={}>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "# Set an experiment (this can be a name you choose for your project)\n",
    "mlflow.set_experiment(\"model_comparison_experiment\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f9d17c7-0db1-4ebc-b89f-101c6154f233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill na with mean depending on column\n",
    "def replaceNAWithMean(df, column):\n",
    "    df[column] = df[column].fillna(df[column].mean())\n",
    "\n",
    "def replaceNAWithMode(df, column):\n",
    "    df[column] = df[column].fillna(df[column].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "719c9fa8-d180-45ea-8631-5e9aae5cf72e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- rbc ---\n",
      "[nan 'normal' 'abnormal']\n",
      "---- pc ---\n",
      "['normal' 'abnormal' nan]\n",
      "---- pcc ---\n",
      "['notpresent' 'present' nan]\n",
      "---- ba ---\n",
      "['notpresent' 'present' nan]\n",
      "---- pcv ---\n",
      "['44' '38' '31' '32' '35' '39' '36' '33' '29' '28' nan '16' '24' '37' '30'\n",
      " '34' '40' '45' '27' '48' '\\t?' '52' '14' '22' '18' '42' '17' '46' '23'\n",
      " '19' '25' '41' '26' '15' '21' '43' '20' '\\t43' '47' '9' '49' '50' '53'\n",
      " '51' '54']\n",
      "---- wc ---\n",
      "['7800' '6000' '7500' '6700' '7300' nan '6900' '9600' '12100' '4500'\n",
      " '12200' '11000' '3800' '11400' '5300' '9200' '6200' '8300' '8400' '10300'\n",
      " '9800' '9100' '7900' '6400' '8600' '18900' '21600' '4300' '8500' '11300'\n",
      " '7200' '7700' '14600' '6300' '\\t6200' '7100' '11800' '9400' '5500' '5800'\n",
      " '13200' '12500' '5600' '7000' '11900' '10400' '10700' '12700' '6800'\n",
      " '6500' '13600' '10200' '9000' '14900' '8200' '15200' '5000' '16300'\n",
      " '12400' '\\t8400' '10500' '4200' '4700' '10900' '8100' '9500' '2200'\n",
      " '12800' '11200' '19100' '\\t?' '12300' '16700' '2600' '26400' '8800'\n",
      " '7400' '4900' '8000' '12000' '15700' '4100' '5700' '11500' '5400' '10800'\n",
      " '9900' '5200' '5900' '9300' '9700' '5100' '6600']\n",
      "---- rc ---\n",
      "['5.2' nan '3.9' '4.6' '4.4' '5' '4.0' '3.7' '3.8' '3.4' '2.6' '2.8' '4.3'\n",
      " '3.2' '3.6' '4' '4.1' '4.9' '2.5' '4.2' '4.5' '3.1' '4.7' '3.5' '6.0'\n",
      " '5.0' '2.1' '5.6' '2.3' '2.9' '2.7' '8.0' '3.3' '3.0' '3' '2.4' '4.8'\n",
      " '\\t?' '5.4' '6.1' '6.2' '6.3' '5.1' '5.8' '5.5' '5.3' '6.4' '5.7' '5.9'\n",
      " '6.5']\n",
      "---- htn ---\n",
      "['yes' 'no' nan]\n",
      "---- dm ---\n",
      "['yes' 'no' ' yes' '\\tno' '\\tyes' nan]\n",
      "---- cad ---\n",
      "['no' 'yes' '\\tno' nan]\n",
      "---- appet ---\n",
      "['good' 'poor' nan]\n",
      "---- pe ---\n",
      "['no' 'yes' nan]\n",
      "---- ane ---\n",
      "['no' 'yes' nan]\n",
      "---- classification ---\n",
      "['ckd' 'notckd']\n",
      "---- rbc ---\n",
      "[nan 'normal' 'abnormal']\n",
      "---- pc ---\n",
      "['normal' 'abnormal' nan]\n",
      "---- pcc ---\n",
      "['notpresent' 'present' nan]\n",
      "---- ba ---\n",
      "['notpresent' 'present' nan]\n",
      "---- pcv ---\n",
      "['44' '38' '31' '32' '35' '39' '36' '33' '29' '28' nan '16' '24' '37' '30'\n",
      " '34' '40' '45' '27' '48' '0' '52' '14' '22' '18' '42' '17' '46' '23' '19'\n",
      " '25' '41' '26' '15' '21' '43' '20' '47' '9' '49' '50' '53' '51' '54']\n",
      "---- wc ---\n",
      "['7800' '6000' '7500' '6700' '7300' nan '6900' '9600' '12100' '4500'\n",
      " '12200' '11000' '3800' '11400' '5300' '9200' '6200' '8300' '8400' '10300'\n",
      " '9800' '9100' '7900' '6400' '8600' '18900' '21600' '4300' '8500' '11300'\n",
      " '7200' '7700' '14600' '6300' '7100' '11800' '9400' '5500' '5800' '13200'\n",
      " '12500' '5600' '7000' '11900' '10400' '10700' '12700' '6800' '6500'\n",
      " '13600' '10200' '9000' '14900' '8200' '15200' '5000' '16300' '12400'\n",
      " '10500' '4200' '4700' '10900' '8100' '9500' '2200' '12800' '11200'\n",
      " '19100' '0' '12300' '16700' '2600' '26400' '8800' '7400' '4900' '8000'\n",
      " '12000' '15700' '4100' '5700' '11500' '5400' '10800' '9900' '5200' '5900'\n",
      " '9300' '9700' '5100' '6600']\n",
      "---- rc ---\n",
      "['5.2' nan '3.9' '4.6' '4.4' '5' '4.0' '3.7' '3.8' '3.4' '2.6' '2.8' '4.3'\n",
      " '3.2' '3.6' '4' '4.1' '4.9' '2.5' '4.2' '4.5' '3.1' '4.7' '3.5' '6.0'\n",
      " '5.0' '2.1' '5.6' '2.3' '2.9' '2.7' '8.0' '3.3' '3.0' '3' '2.4' '4.8' '0'\n",
      " '5.4' '6.1' '6.2' '6.3' '5.1' '5.8' '5.5' '5.3' '6.4' '5.7' '5.9' '6.5']\n",
      "---- htn ---\n",
      "['yes' 'no' nan]\n",
      "---- dm ---\n",
      "['yes' 'no' ' yes' nan]\n",
      "---- cad ---\n",
      "['no' 'yes' nan]\n",
      "---- appet ---\n",
      "['good' 'poor' nan]\n",
      "---- pe ---\n",
      "['no' 'yes' nan]\n",
      "---- ane ---\n",
      "['no' 'yes' nan]\n",
      "---- classification ---\n",
      "['ckd' 'notckd']\n"
     ]
    }
   ],
   "source": [
    "# clean ckd\\t\n",
    "kidney_disease_medical_data.replace('ckd\\t', 'ckd', inplace=True)\n",
    "\n",
    "kidney_disease_medical_data['classification'].value_counts()\n",
    "\n",
    "for c in kidney_disease_medical_data.select_dtypes('object').columns:\n",
    "    print(f\"---- {c} ---\")\n",
    "    print(kidney_disease_medical_data[c].unique())\n",
    "\n",
    "# clean data with \"\\t\" in it\n",
    "kidney_disease_medical_data = kidney_disease_medical_data.replace(r'\\t', '', regex=True)\n",
    "\n",
    "\n",
    "# replace ? with 0\n",
    "\n",
    "kidney_disease_medical_data = kidney_disease_medical_data.replace('?', '0')\n",
    "\n",
    "for c in kidney_disease_medical_data.select_dtypes('object').columns:\n",
    "    print(f\"---- {c} ---\")\n",
    "    print(kidney_disease_medical_data[c].unique())\n",
    "\n",
    "# remove space\n",
    "kidney_disease_medical_data['dm'] = kidney_disease_medical_data['dm'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6859839c-7f35-4561-9d3d-530802efba0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace missing values in numeric columns with mean of column\n",
    "for col in kidney_disease_medical_data[['bp', 'rbc', 'rc', 'wc', 'pcv', 'cad', 'appet', 'sc', 'sod', 'pot', 'hemo', 'htn', 'dm', 'ane', 'age', 'pe']].select_dtypes(exclude='object').columns:\n",
    "    replaceNAWithMean(kidney_disease_medical_data, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15559822-235b-4c35-bf7e-2c31ec778e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace missing values in object columns with mode or most frequently occuring value\n",
    "for col in kidney_disease_medical_data[['bp', 'rbc', 'rc', 'wc', 'pcv', 'cad', 'appet', 'sc', 'sod', 'pot', 'hemo', 'htn', 'dm', 'ane', 'age', 'pe']].select_dtypes('object').columns:\n",
    "    replaceNAWithMode(kidney_disease_medical_data, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "202ba1dd-0e16-4668-bcef-32b3fc0f0ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns to train model on and preprocess data\n",
    "X_features = ['bp', 'rbc', 'rc', 'wc', 'pcv', 'cad', 'appet', 'sc', 'sod', 'pot', 'hemo', 'htn', 'dm', 'ane', 'age', 'pe']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "27b2e84e-5b56-4a5d-b16a-67e434ba803a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert pcv, wc and rc into float\n",
    "kidney_disease_medical_data[['pcv', 'wc', 'rc']] = kidney_disease_medical_data[['pcv', 'wc', 'rc']].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ed4dc872-9eb7-4b7e-8f3f-cad7217a7b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = kidney_disease_medical_data[X_features]\n",
    "y = kidney_disease_medical_data['classification']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e1558c59-a0d4-4841-a1a8-6864ddf42e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature engineer columns\n",
    "X = pd.get_dummies(X, drop_first=True, columns=['rbc', 'cad', 'appet', 'htn', 'dm', 'ane', 'pe'])\n",
    "y = kidney_disease_medical_data['classification']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a1286896-c96e-4087-aa32-8c5275c92bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_enc = LabelEncoder()\n",
    "y = label_enc.fit_transform(y) # convert classification to 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7457be66-7323-450b-95fa-83261054bb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "from sklearn.model_selection import train_test_split\n",
    "# from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42) # split into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bf0a51ae-d4ce-499f-ae46-9fe0efbc5f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ce57ee5c-e291-4469-a52d-a334a60dbba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1aedc892-6654-4b5f-a4e8-43eaa66bd9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = sm.fit_resample(X_train, y_train) # resample training data to fix imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "48d763ac-9654-4369-9d54-a4763a7db311",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m precision_score, recall_score, f1_score\n\u001b[0;32m----> 3\u001b[0m precision \u001b[38;5;241m=\u001b[39m precision_score(y_test, predictions, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmacro\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m recall \u001b[38;5;241m=\u001b[39m recall_score(y_test, predictions, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmacro\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m f1 \u001b[38;5;241m=\u001b[39m f1_score(y_test, predictions, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmacro\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'predictions' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0ca959e9-320f-45be-a79d-5bc583f86013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to train, evaluate, and log models with MLflow\n",
    "def train_and_log_model(model, model_name, params):\n",
    "    with mlflow.start_run(run_name=model_name):\n",
    "        # Log hyperparameters\n",
    "        mlflow.log_params(params)\n",
    "        \n",
    "        # Train the model\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Make predictions and calculate accuracy\n",
    "        predictions = model.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, predictions)\n",
    "\n",
    "        precision = precision_score(y_test, predictions, average=\"macro\")\n",
    "        recall = recall_score(y_test, predictions, average=\"macro\")\n",
    "        f1 = f1_score(y_test, predictions, average=\"macro\")\n",
    "        \n",
    "        # Log the accuracy metric\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "        mlflow.log_metric(\"precision\", precision)\n",
    "        mlflow.log_metric(\"recall\", recall)\n",
    "        mlflow.log_metric(\"f1_score\", f1)\n",
    "        \n",
    "        # Log the model itself\n",
    "        mlflow.sklearn.log_model(model, model_name)\n",
    "        \n",
    "        print(f\"{model_name} accuracy: {accuracy:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7b007c9d-824a-4dcb-864b-f88186e80f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/26 01:47:33 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTree accuracy: 0.9667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/26 01:47:34 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/26 01:47:35 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoosting accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/26 01:47:36 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression accuracy: 0.9917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/26 01:47:37 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaiveBayes accuracy: 0.9333\n"
     ]
    }
   ],
   "source": [
    "# Train and log a Decision Tree model\n",
    "dt_params = {\"max_depth\": 5}\n",
    "dt_model = DecisionTreeClassifier(**dt_params)\n",
    "train_and_log_model(dt_model, \"DecisionTree\", dt_params)\n",
    "\n",
    "# Train and log a Random Forest model\n",
    "rf_params = {\"n_estimators\": 100, \"max_depth\": 5}\n",
    "rf_model = RandomForestClassifier(**rf_params)\n",
    "train_and_log_model(rf_model, \"RandomForest\", rf_params)\n",
    "\n",
    "# Train and log a Gradient Boosting model\n",
    "gb_params = {\"n_estimators\": 100, \"learning_rate\": 0.1, \"max_depth\": 3}\n",
    "gb_model = GradientBoostingClassifier(**gb_params)\n",
    "train_and_log_model(gb_model, \"GradientBoosting\", gb_params)\n",
    "\n",
    "# Train and log a Logistic Regression model\n",
    "lr_params = {\"solver\": \"liblinear\", \"penalty\": \"l2\", \"C\": 1.0}\n",
    "lr_model = LogisticRegression(**lr_params)\n",
    "train_and_log_model(lr_model, \"LogisticRegression\", lr_params)\n",
    "\n",
    "# Train and log a Naive Bayes model\n",
    "nb_params = {}\n",
    "nb_model = GaussianNB(**nb_params)\n",
    "train_and_log_model(nb_model, \"NaiveBayes\", nb_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f57211d-5a0c-4d2a-950f-a067c0c2e638",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
